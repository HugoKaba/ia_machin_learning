{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f034bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdadf88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Préparation des données\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "train_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13962767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Modèles\n",
    "class MNISTMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),              # [batch,1,28,28] -> [batch,784]\n",
    "            nn.Linear(28*28, 512),     # 784 -> 512\n",
    "            nn.ReLU(),                 # activation\n",
    "            nn.Dropout(0.2),           # régularisation\n",
    "            nn.Linear(512, 256),       # 512 -> 256\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),       # 256 -> 128\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 10)         # 128 -> 10 (10 classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)            # sortie : 10 scores (logits)\n",
    "\n",
    "class MNISTCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), # image 1x28x28 -> 32x28x28\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                # 32x28x28 -> 32x14x14\n",
    "            nn.Conv2d(32, 64, 3, padding=1),# 32x14x14 -> 64x14x14\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)                 # 64x14x14 -> 64x7x7\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),                   # 64x7x7 -> 3136\n",
    "            nn.Linear(64*7*7, 128),         # 3136 -> 128\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 10)              # 128 -> 10 (10 classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.fc(x)                   # sortie : 10 scores (logits)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "872006d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Entraînement\n",
    "def train(model, loader, optimizer, loss_fn, device, epoch, prefix):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (X, y) in enumerate(loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % 100 == 0:\n",
    "            n_iter = epoch * len(loader) + batch_idx\n",
    "            writer.add_scalar(f\"Loss/{prefix}_train\", loss.item(), n_iter)\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "def test(model, loader, device, epoch, prefix):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            correct += (pred.argmax(1) == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    acc = correct / total\n",
    "    writer.add_scalar(f\"Accuracy/{prefix}_test\", acc, epoch)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d55004e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 TensorBoard writer\n",
    "writer = SummaryWriter(\"runs/mnist_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27ce1f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Epoch 1: Test accuracy = 0.9331\n",
      "MLP Epoch 2: Test accuracy = 0.9611\n",
      "MLP Epoch 3: Test accuracy = 0.9647\n",
      "MLP Epoch 4: Test accuracy = 0.9697\n",
      "MLP Epoch 5: Test accuracy = 0.9723\n",
      "MLP Epoch 6: Test accuracy = 0.9776\n",
      "MLP Epoch 7: Test accuracy = 0.9755\n",
      "MLP Epoch 8: Test accuracy = 0.9772\n",
      "MLP Epoch 9: Test accuracy = 0.9750\n",
      "MLP Epoch 10: Test accuracy = 0.9780\n"
     ]
    }
   ],
   "source": [
    "# MLP\n",
    "epochs = 10\n",
    "mlp = MNISTMLP().to(device)\n",
    "optimizer_mlp = optim.Adam(mlp.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "for epoch in range(epochs):\n",
    "    train(mlp, train_loader, optimizer_mlp, loss_fn, device, epoch, \"MLP\")\n",
    "    acc = test(mlp, test_loader, device, epoch, \"MLP\")\n",
    "    print(f\"MLP Epoch {epoch+1}: Test accuracy = {acc:.4f}\")\n",
    "    if epoch == 0 or epoch == epochs-1:\n",
    "        mlp.eval()\n",
    "        images, labels = next(iter(test_loader))\n",
    "        images = images.to(device)\n",
    "        outputs = mlp(images)\n",
    "        preds = outputs.argmax(1)\n",
    "        img_grid = utils.make_grid(images[:16].cpu(), nrow=4, normalize=True)\n",
    "        writer.add_image('MNIST MLP Images', img_grid, epoch)\n",
    "        writer.add_text('MLP Predictions', str(preds[:16].cpu().numpy()), epoch)\n",
    "        writer.add_text('MLP Labels', str(labels[:16].cpu().numpy()), epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cef57227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Epoch 1: Test accuracy = 0.9834\n",
      "CNN Epoch 2: Test accuracy = 0.9866\n",
      "CNN Epoch 3: Test accuracy = 0.9888\n",
      "CNN Epoch 4: Test accuracy = 0.9902\n",
      "CNN Epoch 5: Test accuracy = 0.9908\n",
      "CNN Epoch 6: Test accuracy = 0.9910\n",
      "CNN Epoch 7: Test accuracy = 0.9907\n",
      "CNN Epoch 8: Test accuracy = 0.9923\n",
      "CNN Epoch 9: Test accuracy = 0.9914\n",
      "CNN Epoch 10: Test accuracy = 0.9911\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "cnn = MNISTCNN().to(device)\n",
    "optimizer_cnn = optim.Adam(cnn.parameters(), lr=1e-3)\n",
    "for epoch in range(epochs):\n",
    "    train(cnn, train_loader, optimizer_cnn, loss_fn, device, epoch, \"CNN\")\n",
    "    acc = test(cnn, test_loader, device, epoch, \"CNN\")\n",
    "    print(f\"CNN Epoch {epoch+1}: Test accuracy = {acc:.4f}\")\n",
    "    if epoch == 0 or epoch == epochs-1:\n",
    "        cnn.eval()\n",
    "        images, labels = next(iter(test_loader))\n",
    "        images = images.to(device)\n",
    "        outputs = cnn(images)\n",
    "        preds = outputs.argmax(1)\n",
    "        img_grid = utils.make_grid(images[:16].cpu(), nrow=4, normalize=True)\n",
    "        writer.add_image('MNIST CNN Images', img_grid, epoch)\n",
    "        writer.add_text('CNN Predictions', str(preds[:16].cpu().numpy()), epoch)\n",
    "        writer.add_text('CNN Labels', str(labels[:16].cpu().numpy()), epoch)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799cd023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Sauvegarde des modèles\n",
    "torch.save(mlp.state_dict(), \"mnistmlp.pth\")\n",
    "torch.save(cnn.state_dict(), \"mnistcnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "399b5995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Export ONNX\n",
    "mlp.eval()\n",
    "cnn.eval()\n",
    "dummy = torch.randn(1, 1, 28, 28, device='cpu')\n",
    "torch.onnx.export(mlp, dummy, \"mnistmlp.onnx\", input_names=[\"input\"], output_names=[\"output\"], opset_version=13)\n",
    "torch.onnx.export(cnn, dummy, \"mnistcnn.onnx\", input_names=[\"input\"], output_names=[\"output\"], opset_version=13)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
